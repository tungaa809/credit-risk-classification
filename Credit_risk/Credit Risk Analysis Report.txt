The classification report provides a detailed summary of the model's performance on the testing data. Here's what each section of the report means:

Precision: Precision measures the accuracy of the positive class (label 1) predictions. In this case, it's 0.84 for label 1, 
which means that out of all the instances predicted as high-risk loans, 84% are correctly predicted.

Recall: Recall (also known as sensitivity) measures the model's ability to capture all the positive instances. 
A recall of 0.99 for label 1 means that the model correctly identifies 99% of the actual high-risk loans.

F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. 
An F1-score of 0.91 for label 1 is quite good, indicating a balance between precision and recall.

Support: Support represents the number of instances in each class (0 and 1).

Accuracy: Overall accuracy of the model on the testing data is 99%, which means it correctly predicts the majority of instances.

Macro Avg: This is the average of precision, recall, and F1-score for both classes (0 and 1). For macro average precision and recall, it's 0.92 and 0.99, respectively.

Weighted Avg: Weighted average precision, recall, and F1-score take into account the class distribution. 
Since class 0 has many more instances than class 1, weighted average considers the class imbalance. 
The weighted average F1-score of 0.99 indicates excellent overall performance, considering class distribution.

In summary, the model performs very well on the testing data, with high precision, recall, and 
F1-score for both classes. It correctly identifies the majority of high-risk loans while maintaining a high level of precision. 
However, it's important to consider other aspects of model evaluation, such as the business context and the cost of false positives and false negatives, 
when determining the model's suitability for a specific application.
The logistic regression model, trained with oversampled data, performs quite well in predicting both the 0 (healthy loan) and 1 (high-risk loan) labels. 
Here's a breakdown of its performance:

For Label 0 (Healthy Loan):

Precision: 1.00 (100%)
Recall: 0.99 (99%)
F1-score: 1.00 (100%)
This indicates that the model is extremely accurate in identifying healthy loans. 
It correctly identifies 99% of actual healthy loans (high recall), and when it predicts a loan as healthy, it's almost always correct (high precision).

For Label 1 (High-Risk Loan):

Precision: 0.84 (84%)
Recall: 0.99 (99%)
F1-score: 0.91 (91%)
The model also performs well in identifying high-risk loans. While the precision is slightly lower compared to the recall, it still maintains a good balance between 
precision and recall with an F1-score of 0.91. This means that it correctly identifies the majority of high-risk loans while maintaining a reasonable level of precision.

Overall, the logistic regression model trained with oversampled data exhibits strong predictive performance for both healthy loans and high-risk loans. 
It's particularly effective at minimizing false negatives (high recall) for high-risk loans, which is often crucial in risk assessment scenarios. 
However, it's important to consider the specific business context and any associated costs of false positives and false negatives when evaluating the 
model's performance in practice.